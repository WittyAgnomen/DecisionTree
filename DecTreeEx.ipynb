{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building and Using a Decision Tree to Claissify"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A <b>decision tree</b> is a flowchart-like structure in which each internal node represents a \"test\" (<i>a question</i>) on an attribute (<i>example: is gender female?</i>), each branch represents the outcome of the test and each leaf node represents a class label (decision taken after computing all attributes). The paths from root to leaf represents classification rules.\n",
    "\n",
    "For this notebook, we are going to look at some purchase data for an online retailer and use a decision tree to help us classify whether a customer will make a purchase this month. This example will not use any python libraries for machine learning, instead we will build simple functions to do the classification. \n",
    "\n",
    "Also, this notebook will use python code from this <a href=\"https://github.com/arthur-e/Programming-Collective-Intelligence/blob/master/chapter7/treepredict.py\">Github</a> page.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Is a premium member (if they are the get free shipping)</th>\n",
       "      <th>Amount spent since the start of the year</th>\n",
       "      <th>Made a purchase in the current month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>45</td>\n",
       "      <td>Member</td>\n",
       "      <td>3000</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>40</td>\n",
       "      <td>Non</td>\n",
       "      <td>150</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M</td>\n",
       "      <td>24</td>\n",
       "      <td>Non</td>\n",
       "      <td>20</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M</td>\n",
       "      <td>27</td>\n",
       "      <td>Member</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>F</td>\n",
       "      <td>30</td>\n",
       "      <td>Non</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>F</td>\n",
       "      <td>60</td>\n",
       "      <td>Non</td>\n",
       "      <td>38</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>F</td>\n",
       "      <td>19</td>\n",
       "      <td>Member</td>\n",
       "      <td>12</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>F</td>\n",
       "      <td>26</td>\n",
       "      <td>Member</td>\n",
       "      <td>170</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>F</td>\n",
       "      <td>32</td>\n",
       "      <td>Member</td>\n",
       "      <td>1987</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>F</td>\n",
       "      <td>29</td>\n",
       "      <td>Non</td>\n",
       "      <td>300</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>F</td>\n",
       "      <td>39</td>\n",
       "      <td>Member</td>\n",
       "      <td>432</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>F</td>\n",
       "      <td>34</td>\n",
       "      <td>Non</td>\n",
       "      <td>300</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Gender  Age Is a premium member (if they are the get free shipping)  \\\n",
       "0       M   45                                             Member        \n",
       "1       M   40                                                Non        \n",
       "2       M   24                                                Non        \n",
       "3       M   27                                             Member        \n",
       "4       F   30                                                Non        \n",
       "5       F   60                                                Non        \n",
       "6       F   19                                             Member        \n",
       "7       F   26                                             Member        \n",
       "8       F   32                                             Member        \n",
       "9       F   29                                                Non        \n",
       "10      F   39                                             Member        \n",
       "11      F   34                                                Non        \n",
       "\n",
       "    Amount spent since the start of the year  \\\n",
       "0                                       3000   \n",
       "1                                        150   \n",
       "2                                         20   \n",
       "3                                          0   \n",
       "4                                          0   \n",
       "5                                         38   \n",
       "6                                         12   \n",
       "7                                        170   \n",
       "8                                       1987   \n",
       "9                                        300   \n",
       "10                                       432   \n",
       "11                                       300   \n",
       "\n",
       "   Made a purchase in the current month   \n",
       "0                                    Yes  \n",
       "1                                    Yes  \n",
       "2                                     No  \n",
       "3                                     No  \n",
       "4                                     No  \n",
       "5                                     No  \n",
       "6                                     No  \n",
       "7                                    Yes  \n",
       "8                                    Yes  \n",
       "9                                    Yes  \n",
       "10                                   Yes  \n",
       "11                                    No  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#import data from csv\n",
    "data=pd.read_csv('purchase.csv')\n",
    "\n",
    "#save catergories\n",
    "cats=list(data.columns.values)\n",
    "\n",
    "#look at data\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding the Data\n",
    "\n",
    "Before we begin, let's try to understand what the data is. We have 12 observations with each observation being a customer for an online retailer. For each customer, we know their gender, whether they are a premium member (think Prime), amount of money in dollars they have spent since the new year started, and whether they have made a purchase in the current month. \n",
    "\n",
    "We will make that last column the attribute we are trying to classify. In other words, we will want to use the other attributes from the data to see if we could predict whether a customer would make a purchase this month. This is obviously a toy example, but it will highlight how to use a decision tree and can easily be applied to much more data.\n",
    "\n",
    "<b>A side note:</b> We could easily split this data into subgroups with pandas filter function; however, we want to do things ourselves here, so we will convert the table above into a list of lists. Where each row will be a list making up up an element in the larger list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['M', 45, 'Member', 3000, 'Yes'],\n",
       " ['M', 40, 'Non', 150, 'Yes'],\n",
       " ['M', 24, 'Non', 20, 'No'],\n",
       " ['M', 27, 'Member', 0, 'No'],\n",
       " ['F', 30, 'Non', 0, 'No'],\n",
       " ['F', 60, 'Non', 38, 'No'],\n",
       " ['F', 19, 'Member', 12, 'No'],\n",
       " ['F', 26, 'Member', 170, 'Yes'],\n",
       " ['F', 32, 'Member', 1987, 'Yes'],\n",
       " ['F', 29, 'Non', 300, 'Yes'],\n",
       " ['F', 39, 'Member', 432, 'Yes'],\n",
       " ['F', 34, 'Non', 300, 'No']]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#turn panda data frame in list of lists\n",
    "import numpy as np\n",
    "data=data.as_matrix().tolist()\n",
    "\n",
    "#show data\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## GOAL\n",
    "\n",
    "The goal is to use the current data to build a model with a tree structure that will classify additional observations. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plan\n",
    "\n",
    "This notebook will:\n",
    "<ul>\n",
    "  <li>Split the dataset into children sets i.e. from a list of all customers, return 2 subgroups based on a criterion we give (e.g. criterion \"are they female ?\")</li>\n",
    "  <li>Introduce entropy as it gives us a criterion to decide where to split </li>\n",
    "  <li>Build a tree recursively. We cut, then cut the subgroups, and cut the sub-subgroups, etc</li>\n",
    "  <li>Represent the decision trees graphically</li>\n",
    "  <li> Use the built tree to classify new observations</li>\n",
    "</ul> \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting a set\n",
    "\n",
    "As a quick reminder, a decision tree is a type of supervised learning algorithm (having a pre-defined target variable, which in this example is whether they have made a purchase in the current month) that is mostly used in classification problems. It works for both categorical and continuous input and output variables. <b>In this technique, we split the population or sample into two or more homogeneous sets (or sub-populations) based on most significant splitter / differentiator in input variables</b>.\n",
    "\n",
    "So let's write a function to divide a set into 2 children sets. We will then try several divisions while keeping in mind that our goal is to have homogeneous groups with regard to the target attribute (whether they have made a purchase in the current month)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Splits a set on a specific column. \n",
    "def splitset(rows,column,split_value):\n",
    "   # Make a function that tells us if a row is in the first group (true) or the second group (false)\n",
    "   split_function=None\n",
    "   # if split_value is a number split groups by true if >= number false if not\n",
    "   if isinstance(split_value,int) or isinstance(split_value,float): \n",
    "      split_function=lambda row:row[column]>=split_value\n",
    "   # if split_value is a string, true if it equals the string value, false otherwise\n",
    "   else:\n",
    "      split_function=lambda row:row[column]==split_value\n",
    "   \n",
    "   # Divide the rows into two sets and return them\n",
    "   set1=[row for row in rows if split_function(row)]\n",
    "   set2=[row for row in rows if not split_function(row)]\n",
    "   return (set1,set2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the split function on the data\n",
    "\n",
    "Below we will test the split function twice. First, we create a split on the test: 'Is the customer female?' Second, we create a split on the test: 'Did the customer spend 1000 dollars or more?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([['F', 30, 'Non', 0, 'No'],\n",
       "  ['F', 60, 'Non', 38, 'No'],\n",
       "  ['F', 19, 'Member', 12, 'No'],\n",
       "  ['F', 26, 'Member', 170, 'Yes'],\n",
       "  ['F', 32, 'Member', 1987, 'Yes'],\n",
       "  ['F', 29, 'Non', 300, 'Yes'],\n",
       "  ['F', 39, 'Member', 432, 'Yes'],\n",
       "  ['F', 34, 'Non', 300, 'No']],\n",
       " [['M', 45, 'Member', 3000, 'Yes'],\n",
       "  ['M', 40, 'Non', 150, 'Yes'],\n",
       "  ['M', 24, 'Non', 20, 'No'],\n",
       "  ['M', 27, 'Member', 0, 'No']])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splitset(data,0,'F')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the above function broke the data into two seperate arrays where one is only the females and the other is only the males."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([['M', 45, 'Member', 3000, 'Yes'], ['F', 32, 'Member', 1987, 'Yes']],\n",
       " [['M', 40, 'Non', 150, 'Yes'],\n",
       "  ['M', 24, 'Non', 20, 'No'],\n",
       "  ['M', 27, 'Member', 0, 'No'],\n",
       "  ['F', 30, 'Non', 0, 'No'],\n",
       "  ['F', 60, 'Non', 38, 'No'],\n",
       "  ['F', 19, 'Member', 12, 'No'],\n",
       "  ['F', 26, 'Member', 170, 'Yes'],\n",
       "  ['F', 29, 'Non', 300, 'Yes'],\n",
       "  ['F', 39, 'Member', 432, 'Yes'],\n",
       "  ['F', 34, 'Non', 300, 'No']])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splitset(data, 3, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This second splitset function has split the data into to arrays where the first holds the pople who spent 1000$ or more and the second less than."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The splitset function splits the data on the test. Now the returned two lists are the child sets for the data fed to the function. Thinking in terms of a decision tree, the idea would be to keep calling the splitset function with a test on child sets until we are only left with homgenous children in the target attribute category. \n",
    "\n",
    "Now we can easily use deciosion trees to split data, we can pick the tests we use, we can exhaust many possibilities in decision tree construction, etc. Yet, that could be extremely costly in terms of time and measuring which decision tree classifier is better would be hard to judge. \n",
    "\n",
    "Therefore, we need to introduce a measuring stick. Some test or concept to aid us in judging wheter the construction of our decision tree is actually good.\n",
    "\n",
    "## Entropy\n",
    "\n",
    "As stated before, the goal is to maximize the homogeneity/purity of each childset for each split with regard to the target attribute. That would enable us to classify future observations well.\n",
    "\n",
    "With that goal in mind, we introduce the concept of entropy. Entropy is basically the contrary of purity/homogenity within a set, with regard to the target attribute. The more mixed up sets are, the higher their entropy. If there are 2 classes, entropy is maximum when a set contains 50% of each class and is null if the set is pure. Our goal is to reduce the entropy of the children sets when we split a set in comparison to the entropy in the parent set. \n",
    "\n",
    "Mathematically, Entropy is the sum of the probability of each label times the log probability of that same label. The Entropy function is found below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# gives the count of units depending on their values in target attribute\n",
    "def uniqcounts(rows):\n",
    "   results={}\n",
    "   for row in rows:\n",
    "      r=row[len(row)-1]\n",
    "      if r not in results: results[r]=0\n",
    "      results[r]+=1\n",
    "   return results\n",
    "\n",
    "# Entropy \n",
    "def entropy(rows):\n",
    "   from math import log\n",
    "   log2=lambda x:log(x)/log(2)  \n",
    "   results=uniqcounts(rows)\n",
    "   # Now calculate the entropy\n",
    "   ent=0.0\n",
    "   for r in results.keys():\n",
    "      p=float(results[r])/len(rows)\n",
    "      ent=ent-p*log2(p)\n",
    "   return ent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 1.0)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check entropy on a test: is the customer female\n",
    "set1,set2=splitset(data,0,'F')\n",
    "entropy(set1), entropy(set2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['F', 30, 'Non', 0, 'No'],\n",
       " ['F', 60, 'Non', 38, 'No'],\n",
       " ['F', 19, 'Member', 12, 'No'],\n",
       " ['F', 26, 'Member', 170, 'Yes'],\n",
       " ['F', 32, 'Member', 1987, 'Yes'],\n",
       " ['F', 29, 'Non', 300, 'Yes'],\n",
       " ['F', 39, 'Member', 432, 'Yes'],\n",
       " ['F', 34, 'Non', 300, 'No']]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['M', 45, 'Member', 3000, 'Yes'],\n",
       " ['M', 40, 'Non', 150, 'Yes'],\n",
       " ['M', 24, 'Non', 20, 'No'],\n",
       " ['M', 27, 'Member', 0, 'No']]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we split data into two children sets called set1 and set2 with a test on gender. As we can see, set 1 and 2 has maximun entropy because it is as far from homogenous as you can be (it has 50 50 split in the target attribute).\n",
    "\n",
    "Side Note: The maximum value of entropy is logk, where k is the number of categories you are using. Its numeric value will naturally depend on the base of logarithms you are using. Using base 2 logarithms as an example: log_2(1) is 0 and log_2(2) is 1, so a result greater than 1 is wrong if the number of categories is 1 or 2. A value greater than 1 will be wrong if it exceeds log_2(k). In view of this, it is fairly common to scale entropy by logk, so that results then do fall between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entropy(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we see that the test we split on above led to neither of the children sets being lower in entropy then the parent set. This means we should split on a different test.\n",
    "\n",
    "Ultimately, the test we split on should be the one that reduces the entropy the most (<i>ofcourse not actully true, sometimes there may be better claissifers that create more entropy in splits first, but we will ignore this here, this is a simple decison tree example</i>). In other words, the split that adds the most information.\n",
    "\n",
    "IG(parent, children) = entropy(parent) - [entropy(child1) x prop(child1) + entropy(child2) x prop(child2)], where prop(childi) is the proportion of instances falling into the childi.\n",
    "\n",
    "## Building a Decision Tree Function\n",
    "\n",
    "Now, We want to build a decision tree function that will use the split function and entropy function. This function will look at one column. It will list all possible values in that column. It then attempts to split and compare the information gain to the best split until now. Then it goes to the next column and does the same. At the end, we keep the best split, i.e. the one who gave us the highest IG i.e. who reduced the most entropy i.e. who formed two homogeneous groups. The algorithm is then recursively applied to build the different branches.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class decisionnode:\n",
    "  def __init__(self,col=-1,value=None,results=None,tb=None,fb=None):\n",
    "    self.col=col\n",
    "    self.value=value\n",
    "    self.results=results\n",
    "    self.tb=tb\n",
    "    self.fb=fb\n",
    "\n",
    "#rows is the set, either whole dataset or part of it in the recursive call, scoref is the method to measure heterogeneity\n",
    "def buildtree(rows,scoref=entropy): \n",
    "                                    \n",
    "  if len(rows)==0: return decisionnode() #len(rows) is the number of units in a set\n",
    "  current_score=scoref(rows)\n",
    "\n",
    "  # Set up some variables to track the best criteria\n",
    "  best_gain=0.0\n",
    "  best_criteria=None\n",
    "  best_sets=None\n",
    "  \n",
    "  column_count=len(rows[0])-1   #count the # of attributes/columns. \n",
    "                                #It's -1 because the last one is the target attribute and it does not count.\n",
    "  for col in range(0,column_count):\n",
    "    # Generate the list of all possible different values in the considered column\n",
    "    global column_values        #Added for debugging\n",
    "    column_values={}            \n",
    "    for row in rows:\n",
    "       column_values[row[col]]=1   \n",
    "    # Now try dividing the rows up for each value in this column\n",
    "    for value in column_values.keys(): #the 'values' here are the keys of the dictionnary\n",
    "      (set1,set2)=splitset(rows,col,value) #define set1 and set2 as the 2 children set of a division\n",
    "      \n",
    "      # Information gain\n",
    "      p=float(len(set1))/len(rows) #p is the size of a child set relative to its parent\n",
    "      gain=current_score-p*scoref(set1)-(1-p)*scoref(set2) #cf. formula information gain\n",
    "      if gain>best_gain and len(set1)>0 and len(set2)>0: #set must not be empty\n",
    "        best_gain=gain\n",
    "        best_criteria=(col,value)\n",
    "        best_sets=(set1,set2)\n",
    "        \n",
    "  # Create the sub branches   \n",
    "  if best_gain>0:\n",
    "    trueBranch=buildtree(best_sets[0])\n",
    "    falseBranch=buildtree(best_sets[1])\n",
    "    return decisionnode(col=best_criteria[0],value=best_criteria[1],\n",
    "                        tb=trueBranch,fb=falseBranch)\n",
    "  else:\n",
    "    return decisionnode(results=uniqcounts(rows))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tree=buildtree(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from PIL import Image,ImageDraw\n",
    "\n",
    "def drawtree(tree,jpeg='tree.jpg'):\n",
    "  w=getwidth(tree)*100\n",
    "  h=getdepth(tree)*100+120\n",
    "\n",
    "  img=Image.new('RGB',(w,h),(255,255,255))\n",
    "  draw=ImageDraw.Draw(img)\n",
    "\n",
    "  drawnode(draw,tree,w/2,20)\n",
    "  img.save(jpeg,'JPEG')\n",
    "  \n",
    "def drawnode(draw,tree,x,y):\n",
    "  if tree.results==None:\n",
    "    # Get the width of each branch\n",
    "    w1=getwidth(tree.fb)*100\n",
    "    w2=getwidth(tree.tb)*100\n",
    "\n",
    "    # Determine the total space required by this node\n",
    "    left=x-(w1+w2)/2\n",
    "    right=x+(w1+w2)/2\n",
    "\n",
    "    # Draw the condition string\n",
    "    draw.text((x-20,y-10),'The test is: '+ str(tree.value) +'?',(0,0,0))\n",
    "\n",
    "    # Draw links to the branches\n",
    "    draw.line((x,y,left+w1/2,y+100),fill=(0,255,0))\n",
    "    draw.line((x,y,right-w2/2,y+100),fill=(0,255,0))\n",
    "    \n",
    "    # Draw the branch nodes\n",
    "    drawnode(draw,tree.fb,left+w1/2,y+100)\n",
    "    drawnode(draw,tree.tb,right-w2/2,y+100)\n",
    "  else:\n",
    "    txt=' \\n'.join(['%s:%d'%v for v in tree.results.items()])\n",
    "    draw.text((x-20,y),txt,(0,0,0))\n",
    "    \n",
    "def getwidth(tree):\n",
    "  if tree.tb==None and tree.fb==None: return 1\n",
    "  return getwidth(tree.tb)+getwidth(tree.fb)\n",
    "\n",
    "def getdepth(tree):\n",
    "  if tree.tb==None and tree.fb==None: return 0\n",
    "  return max(getdepth(tree.tb),getdepth(tree.fb))+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def printtree(tree,indent=''):\n",
    "   # Is this a leaf node?\n",
    "   if tree.results!=None:\n",
    "      print str(tree.results)\n",
    "   else:\n",
    "      # Print the criteria\n",
    "      print str(tree.col)+':'+str(tree.value)+'? '\n",
    "\n",
    "      # Print the branches\n",
    "      print indent+'T->',\n",
    "      printtree(tree.tb,indent+'  ')\n",
    "      print indent+'F->',\n",
    "      printtree(tree.fb,indent+'  ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "drawtree(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Decision Tree\n",
    "<div align=\"left\"> \n",
    "<img src=\"tree.jpg\" alt=\"Tree View\" style=\"width:500px;height:350px;\">  </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3:150? \n",
      "T-> 2:Non? \n",
      "  T-> 0:F? \n",
      "    T-> 1:34? \n",
      "      T-> {'No': 1}\n",
      "      F-> {'Yes': 1}\n",
      "    F-> {'Yes': 1}\n",
      "  F-> {'Yes': 4}\n",
      "F-> {'No': 5}\n"
     ]
    }
   ],
   "source": [
    "printtree(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the tree, we can see the rules to split are: Did the customer spend more than 150 since the beginning of the year, are they not a member, are they female, are they 34 or older.\n",
    "\n",
    "## Decision Tree Classification\n",
    "\n",
    "From this tree we can classify additional customers. The idea is we just use the decision tree to ask the test questions until we get to a leaf node (a node with only one type in the target attribute). Think of the tree as outlining the classification algorthm. \n",
    "\n",
    "Instead of doing the questioning manually, code to ask the questions for us is below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def classify(observation,tree):\n",
    "  if tree.results!=None:\n",
    "    return tree.results\n",
    "  else:\n",
    "    v=observation[tree.col]\n",
    "    branch=None\n",
    "    if isinstance(v,int) or isinstance(v,float):\n",
    "      if v>=tree.value: branch=tree.tb\n",
    "      else: branch=tree.fb\n",
    "    else:\n",
    "      if v==tree.value: branch=tree.tb\n",
    "      else: branch=tree.fb\n",
    "    return classify(observation,branch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying Classification\n",
    "\n",
    "Let's give classifying a try. Imigine we have a 57 year old female customer who is a premium member and spend 100 dollars so far this year. Will she buy something this month?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'No': 5}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify(['F', 57, 'Member', 100,],tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our decision tree classification tells us she will not purchase something this month. How about a 24 year old male who is not a premium member but has spent 270 so far this year?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Yes': 1}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify(['M', 24, 'Non', 270,],tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well thats it. Decision Tree Classification. \n",
    "\n",
    "## Conclusion\n",
    "\n",
    "This is only a intoduction on how to build decision trees. Further topics to explore include how to prune the tree (to avoid overfitting) and dealing with missing datas.\n",
    "\n",
    "Overall decision trees are nice because:\n",
    "<ul>\n",
    "<li>You get a interpretable model where you understand the decision rules</li> \n",
    "<li>You can easily mix categorical and numerical data</li>\n",
    "<li>You don't need much data preparation (no strong assumptions on how the data should look like)</li>\n",
    "\n",
    "One major flaw is they are prone to overfit and may not generalize well.\n",
    "\n",
    "But to end on a good note, this can be mitigated through more advanced technigues that use the decision tree as the underlying tool. Random forest and boosted trees are extremely powerful and start with a basic understanding of decision trees.\n",
    "\n",
    "Also a boosted tree technique called XGBoost is doing really well for itslef on many types of problems. So master decision trees and then master the more advanced techniques to be on your way to creating better learning models. Happy exploring."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
